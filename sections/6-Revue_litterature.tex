\Chapter{REVUE DE LITTÉRATURE / LITERATURE REVIEW}\label{sec:RevLitt}

\section{Trace}

\subsection{Analyse de trace}



Le traçage implique une utilisation spécialisée de la journalisation qui enregistre les événements d'exécution concernant l'exécution d'un programme. Le traçage est utilisé pour détecter et identifier les problèmes de performances, les problèmes de comportement et les problèmes de sécurité (TROUVEZ LA SOURCE ICI). Le traçage peut être effectué à plusieurs niveaux, notamment l'espace utilisateur, le noyau, le matériel, l'hyperviseur, le réseau, etc. Le logiciel qui capture ces événements est appelé traceur. Pour capturer ces événements, les points de trace doivent être insérés de manière statique ou dynamique. Dans le cas où le point de trace est inséré de manière statique, le code doit être modifié pour inclure les macros de traçage et doit être recompilé. Dans le cas où le point de trace est inséré dynamiquement, les points de trace sont ajoutés dynamiquement à un programme compilé et en cours d'exécution \cite{gregg2011dtrace}. Lors de l'exécution du programme, des événements seront émis et un traceur les capturera. À ce stade, un traceur produira un fichier de trace, organisé dans un format spécifique. Étant donné que le traceur doit s'exécuter en même temps que l'application principale, cela aura un impact sur le temps d'exécution de l'application principale. C'est pourquoi un traceur doit avoir une surcharge d'exécution minimale. Lorsque le traceur a fini de produire un fichier de trace, nous pouvons appliquer une analyse de trace.

Linux inclut perf \cite{kernelPerfWiki}, un ensemble d'outils qui utilisent l'infrastructure perf\_event\_open \cite{man7Perf}. Ces outils puissants couvrent un large éventail d'informations liées aux performances disponibles pour le système d'exploitation. Les fonctionnalités disponibles incluent l'échantillonnage basé sur un compteur de performances, certains points d'instrumentation, la journalisation pour enregistrer les informations collectées et la visualisation sous forme de profils textuels. Cependant, perf utilise un format de fichier monolithique et ne dispose pas d'un moyen évolutif et convivial pour analyser et visualiser les délais résultants. Auparavant, nous utilisions perf pour la surveillance des performances et convertissions la trace résultante dans un format de fichier différent permettant l'utilisation d'outils de visualisation de chronologie \cite{schone2014scalable}.



OProfile \cite{sourceforgeAboutOProfile} est un profileur statistique non intrusif construit sur l'infrastructure \textit{perf\_event-\_open}. Il prend en charge la surveillance à faible coût de l'ensemble du système et des processus uniques, mais est limité aux profils agrégés uniquement.

Une analyse de trace transforme les événements de trace en un ensemble de données pour effectuer plus d'investigation et les réorganise en structure de données pour un accès plus rapide \cite{prieur2018r}.

HPCToolkit \cite{adhianto2010hpctoolkit} est une suite d'outils d'analyse des performances qui se concentre sur l'échantillonnage d'applications parallèles, prenant en charge MPI et OpenMP. Il utilise la synthèse pour fournir des profils de performances. De plus, une vue chronologique basée sur la journalisation est disponible. HPCToolkit comprend des informations provenant d'échantillons de pile d'appels qui sont traités dans l'espace utilisateur avec des techniques de déroulement sophistiquées et des compteurs de performances de l'interface de programmation d'applications de performances.

Trace Viewer est une extension open source disponible dans l'IDE Theia. Il utilise le protocole Trace-Server-Protocol pour interroger les modèles de données et visualiser différentes analyses de trace. Une analyse de trace lit une trace de manière séquentielle et stocke ses résultats (appelés modèles d'état) dans une structure de données pouvant être écrite sur disque. À partir des événements de trace, l'analyse extrairait les intervalles des valeurs d'état pour différentes ressources système (CPU, processus, disques, etc.). \cite{chen2021distributed}


\subsection{Outils de visualisation de trace}




\section{Traçage distribué}

\subsection{Système distribué}

\subsection{Outils de traçage distribué}

\subsection{Outils de visualisation de trace distribué}


\section{Architecture distribué}

\subsection{Client-serveur}

\subsection{Pair-à-pair} 

\subsection{Maître-Ouvrier}


\section{Interopérabilité de système hétérogène}

\subsection{REST}

\subsection{GraphQL}

\subsection{JSON-RPC}

\subsection{gRPC}

\subsection{Language Server Protocol (LSP)}


Le Language Server Protocol (LSP) est un protocole de communication basé sur JSON-RPC, développé par Microsoft, qui permet l'interaction entre un éditeur ou un environnement de développement intégré (EDI) et un serveur de langage de programmation \cite{Keidel2016}. Un serveur de langage fournit diverses fonctionnalités telles que l'autocomplétion de code, la coloration syntaxique, la navigation vers la définition, et la signalisation des erreurs dans le code. L'objectif principal du LSP est de standardiser la manière dont ces fonctionnalités sont mises à disposition des EDI. Cela permet de rendre l'implémentation d'un EDI indépendante du serveur de langage, favorisant ainsi la réutilisation des serveurs de langage dans différents EDI. Initialement conçu pour VS Code, le LSP a évolué grâce à la contribution d'organisations telles que Red Hat et Codeenvy. Plusieurs entreprises, dont la fondation Eclipse, Github, Sourcegraph et Red Hat, ont adapté leurs outils de développement populaires, tels qu'Eclipse, Atom, IntelliJ, Emacs, Sublime, pour prendre en charge le protocole. Actuellement, plus de 200 langages de programmation, y compris Java, C/C++, C\#, PHP, Python et JavaScript, prennent en charge le LSP.

Le LSP définit trois types de messages : les requêtes, les réponses et les notifications. Les requêtes sont initiées par le client en utilisant des appels de procédures JSON-RPC, et le serveur répond à chaque requête par une réponse. Les notifications peuvent être envoyées par le serveur ou le client, sans nécessité de réponse. La figure ci-dessous illustre un exemple d'interaction et d'échange de messages entre un EDI et un serveur de langage pendant une session d'édition de code. De plus, le LSP supporte la cancellation de requête et le rapport de progression. Grâce à cela, il est possible de canceller des requêtes en cours et d'obtenir des réponses partielles.

Les interactions entre le client et le serveur se basent sur des modèles indépendants du langage de programmation et de l'EDI. Par exemple, lorsqu'un client souhaite accéder à la définition d'une procédure, il échange un Uniform Resource Identifier (URI) avec le serveur pour localiser un document sur disque et une position dans ce document. Le LSP permet également au serveur de signaler quelles fonctionnalités il prend en charge, laissant au client la gestion de la durée de vie du serveur.

Monto est une architecture qui connecte un EDI à des composants offrant des fonctionnalités de langage, adoptant une approche orientée service. Chaque fonctionnalité de langage, comme l'autocomplétion, est fournie par un service qui peut être décomposé en sous-services. L'architecture permet à l'EDI de connaître les fonctionnalités disponibles enregistrées auprès d'une composante appelée broker. Un module d'extension dans l'EDI gère la communication avec le broker. La figure illustre une vue d'ensemble de l'interaction entre les composants de l'architecture Monto.

L'architecture Monto définit deux types de messages : les messages source et les messages produit. Les messages source, envoyés du module d'extension de l'EDI vers le broker, contiennent un identifiant unique, le nom du fichier, le langage de programmation et le contenu du fichier. Le broker distribue les messages source aux services appropriés et répond au module d'extension de l'EDI lorsque les opérations sont terminées. Les messages produits encapsulent une représentation intermédiaire générique, indépendante du langage et de l'EDI. Les communications sont effectuées via ZeroMQ, une bibliothèque de messagerie asynchrone haute performance, avec l'encodage des messages au format JSON. Cette approche permet d'avoir un serveur sans état et n'exige pas de conserver une copie des documents ouverts, contrairement au LSP. Cependant, l'envoi du contenu complet d'un fichier au format JSON peut ne pas être optimal en termes de transfert de données sur le réseau.

% In the same way, a lot of work as been put to decouple the debugging tools and the IDEs. Microsoft debugger adapter protocol (DAP) is implement in Visual Studio Code and Theia. The base protocol exchanges messages that consist of a header and a content part (comparable to HTTP). Josselin et al. proposed a protocol that supports meaningful Domain-Specific Languages (DSLs) and that can be used with minimal effort within an IDE that implement DAP. This debugger allowing a generic interactive debugger to communicate with heterogeneous DSL runtime \cite{enet2023}. 

% Marr et al. have presented the Kómpos protocol \cite{Marr2017} which proposes a concurrency-agnostic debugger protocol that decouples the debugger from the concurrency models employed by the target application. As a result, the underlying language runtime can define custom breakpoints, stepping operations, and execution events for each concurrency model it supports, and a debugger can expose them without having to be specifically adapted. In comparison to existing debugger protocol such as Java Debug Wire Protocol (JDWP) or the GNU Debugger (GDB) machine interface or the Chrome DevTools protocol or Visual Studio Code debug protocol, Kómpos protocol solution is not specific to a concurrency concept.



\subsection{Language Server Index Format Specification (LSIF)}

\subsection{Trace Server Protocol (TSP)}




\section{Conclusion de la revue littéraire}



% \section{Related Work}

% The related work is divided into six sections. The first section detail recent work on Tracing Analysis. The second section report recent work on integrated development environment. The third section present different distributed architecture that application use for scaling. The fourth section expose recent work on distributed analysis. The fifth section report recent work on distributed critical path. The sixth section present recent work on Theia.

% \subsection{Integrated Development Environment}
% % \subsection{Scaling Distributed Architecture}

% % Modern Internet services are often implemented as complex, large-scale distributed systems. These applications are constructed from collections of software modules that may be developed by different teams, perhaps in different programming languages, and could span many thousands of machines across multiple physical facilities. Tools that aid in understanding system behavior and reasoning about performance issues are invaluable in such an environment.

% % Artificial Intelligence (AI) and cloud computing has emerged as a promising avenue for addressing the growing computational demands of AI applications. Parallel and distributed training of AI models become increasingly complex. Parallel and distributed training techniques have emerged as essential approaches to reduce training time and improve resource utilization. By leveraging these techniques, researchers and practitioners can accelerate the training process, enhance model performance, and reduce costs associated with cloud-based AI systems[Article 11].

% % Resource demands of HPC applications vary significantly. The varying resource demands can lead to HPC resources being not fully utilized. It becomes very difficult for HPC systems to find the reasons for throttling jobs. [Article 13]

% % [Article 14]



% \subsection{Distributed Analysis}

% Recent efforts to parallelize trace analysis, as exemplified by the work of Reumont-Locke (2015) \cite{reumont2015methodes} and Martin (2018) \cite{Martin2018}, have aimed to enhance the efficiency of this process. Nevertheless, optimizing efficiency alone cannot fully address the scalability challenges inherent in distributed environments. Even if a trace analysis tool operates at peak efficiency, it remains constrained by the computational capabilities of the underlying hardware, typically equivalent to the traced system in the best-case scenario. When we scale up the number of traced nodes to hundreds or thousands, the analysis tool quickly becomes overwhelmed. This bottleneck becomes particularly problematic in applications requiring continuous uptime, as anomalies can rapidly escalate within clusters (Matloff) \cite{matloff2011programming}, and delays in data analysis during investigations only exacerbate the situation.

% A similar approach observed in distributed tracing platforms involves deploying multiple tracers, each running on a traced machine, with all trace data being transmitted to a central collector for subsequent analysis. In some instances, these tracers take the form of client libraries, allowing for the creation of custom events with application-specific information, in contrast to the more opaque black-box tracing approach of tools like Nagios. Prometheus addresses scalability concerns by enabling the organization of Prometheus instances into a federation, as demonstrated by Reback in 2021 \cite{Logz.io_prometheus_2023}. This approach facilitates the establishment of a multi-level hierarchy of Prometheus servers, with each level aggregating and forwarding data to the level above. Notably, Nagios also adopted a similar approach to mitigate its own scalability challenges (Nagios) \cite{Nagios2019}.

% While horizontally scaling analysis servers is an effective strategy, it is essential to recognize that Prometheus analyses primarily consist of simple metrics, making aggregation feasible. However, applying the same model to more complex analysis processes, such as those offered by Trace Compass, presents substantial challenges. The nature of their aggregations varies significantly between different analysis types, making direct application of the Prometheus approach difficult in such cases.

% \subsection{Distributed Critical Path}

% Recent efforts to parallelize critical path analysis, as exemplified by the work of Denis and Dagenais, have aimed to enhance the efficiency of this process. The kernel events necessary for analysis execution are identified. A distributed architecture that did not require any file transfer between the client and traced nodes, and allowed the distribution of trace analysis computation is presented. They also explore the algorithm to resolve the remote dependencies \cite{matloff2011programming}.

% Although distributed architectures offer a solution to the scalability problem, it is challenging to fully leverage their benefits due to network communication when broadcasting to all nodes. This is why restricting communications solely to the node essential for the calculation is crucial \cite{denys2023distributed}.


% \subsection{Theia - Trace Viewer Extension}

% Eﬀtinge and Kosyakov have presented Theia (Eﬀtinge and Kosyakov, 2017), a new open-
% source IDE framework for building IDEs that could run both as a desktop application or in
% a web browser connected to a remote backend. The project shares a lot of similarities with
% Microsoft code editor, Visual Studio Code. Theia uses Node.js, Electron and implements
% the LSP.


% Theia Trace Viewer extension is the newly developed server-client application developed by Ericsson and the Eclipse Foundation, along with other contributors. It purpose is to replace Trace Compass as the Eclipse general-purpose tracing tool. As previously described Trace Viewer uses a server-client architecture, where the client communicates with the server through a protocol called Trace Server Protocol (TSP) \cite{desnoyers2006lttng}.
