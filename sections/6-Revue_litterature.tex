\Chapter{REVUE DE LITTÉRATURE / LITERATURE REVIEW}\label{sec:RevLitt}

\section{Trace}

\subsection{Analyse de trace}



Le traçage implique une utilisation spécialisée de la journalisation qui enregistre les événements d'exécution concernant l'exécution d'un programme. Le traçage est utilisé pour détecter et identifier les problèmes de performances, les problèmes de comportement et les problèmes de sécurité (TROUVEZ LA SOURCE ICI). Le traçage peut être effectué à plusieurs niveaux, notamment l'espace utilisateur, le noyau, le matériel, l'hyperviseur, le réseau, etc. Le logiciel qui capture ces événements est appelé traceur. Pour capturer ces événements, les points de trace doivent être insérés de manière statique ou dynamique. Dans le cas où le point de trace est inséré de manière statique, le code doit être modifié pour inclure les macros de traçage et doit être recompilé. Dans le cas où le point de trace est inséré dynamiquement, les points de trace sont ajoutés dynamiquement à un programme compilé et en cours d'exécution \cite{gregg2011dtrace}. Lors de l'exécution du programme, des événements seront émis et un traceur les capturera. À ce stade, un traceur produira un fichier de trace, organisé dans un format spécifique. Étant donné que le traceur doit s'exécuter en même temps que l'application principale, cela aura un impact sur le temps d'exécution de l'application principale. C'est pourquoi un traceur doit avoir une surcharge d'exécution minimale. Lorsque le traceur a fini de produire un fichier de trace, nous pouvons appliquer une analyse de trace.

Linux inclut perf \cite{kernelPerfWiki}, un ensemble d'outils qui utilisent l'infrastructure perf\_event\_open \cite{man7Perf}. Ces outils puissants couvrent un large éventail d'informations liées aux performances disponibles pour le système d'exploitation. Les fonctionnalités disponibles incluent l'échantillonnage basé sur un compteur de performances, certains points d'instrumentation, la journalisation pour enregistrer les informations collectées et la visualisation sous forme de profils textuels. Cependant, perf utilise un format de fichier monolithique et ne dispose pas d'un moyen évolutif et convivial pour analyser et visualiser les délais résultants. Auparavant, nous utilisions perf pour la surveillance des performances et convertissions la trace résultante dans un format de fichier différent permettant l'utilisation d'outils de visualisation de chronologie \cite{schone2014scalable}.



OProfile \cite{sourceforgeAboutOProfile} est un profileur statistique non intrusif construit sur l'infrastructure \textit{perf\_event-\_open}. Il prend en charge la surveillance à faible coût de l'ensemble du système et des processus uniques, mais est limité aux profils agrégés uniquement.

Une analyse de trace transforme les événements de trace en un ensemble de données pour effectuer plus d'investigation et les réorganise en structure de données pour un accès plus rapide \cite{prieur2018r}.

HPCToolkit \cite{adhianto2010hpctoolkit} est une suite d'outils d'analyse des performances qui se concentre sur l'échantillonnage d'applications parallèles, prenant en charge MPI et OpenMP. Il utilise la synthèse pour fournir des profils de performances. De plus, une vue chronologique basée sur la journalisation est disponible. HPCToolkit comprend des informations provenant d'échantillons de pile d'appels qui sont traités dans l'espace utilisateur avec des techniques de déroulement sophistiquées et des compteurs de performances de l'interface de programmation d'applications de performances.

Trace Viewer est une extension open source disponible dans l'IDE Theia. Il utilise le protocole Trace-Server-Protocol pour interroger les modèles de données et visualiser différentes analyses de trace. Une analyse de trace lit une trace de manière séquentielle et stocke ses résultats (appelés modèles d'état) dans une structure de données pouvant être écrite sur disque. À partir des événements de trace, l'analyse extrairait les intervalles des valeurs d'état pour différentes ressources système (CPU, processus, disques, etc.). \cite{chen2021distributed}


\subsection{Outils de visualisation de trace}




\section{Traçage distribué}

\subsection{Système distribué}

\subsection{Outils de traçage distribué}

\subsection{Outils de visualisation de trace distribué}


\section{Architecture distribué}

\subsection{Client-serveur}

\subsection{Pair-à-pair} 

\subsection{Maître-Ouvrier}


\section{Interopérabilité de système hétérogène}

\subsection{REST}

\subsection{GraphQL}

\subsection{JSON-RPC}

\subsection{gRPC}

\subsection{Language Server Protocol}

Le Language Server Protocol (LSP) est un protocole de communication basé sur JSON-RPC, développé par Microsoft, qui permet l'interaction entre un éditeur ou un environnement de développement intégré (EDI) et un serveur de langage de programmation \cite{Keidel2016}. Un serveur de langage fournit diverses fonctionnalités telles que l'autocomplétion de code, la coloration syntaxique, la navigation vers la définition, et la signalisation des erreurs dans le code. L'objectif principal du LSP est de standardiser la manière dont ces fonctionnalités sont mises à disposition des EDI. Cela permet de rendre l'implémentation d'un EDI indépendante du serveur de langage, favorisant ainsi la réutilisation des serveurs de langage dans différents EDI. Initialement conçu pour VS Code, le LSP a évolué grâce à la contribution d'organisations telles que Red Hat et Codeenvy. Plusieurs entreprises, dont la fondation Eclipse, Github, Sourcegraph et Red Hat, ont adapté leurs outils de développement populaires, tels qu'Eclipse, Atom, IntelliJ, Emacs, Sublime, pour prendre en charge le protocole. Actuellement, plus de 200 langages de programmation, y compris Java, C/C++, C\#, PHP, Python et JavaScript, prennent en charge le LSP.

Le LSP définit trois types de messages : les requêtes, les réponses et les notifications. Les requêtes sont initiées par le client en utilisant des appels de procédures JSON-RPC, et le serveur répond à chaque requête par une réponse. Les notifications peuvent être envoyées par le serveur ou le client, sans nécessité de réponse. La figure ci-dessous illustre un exemple d'interaction et d'échange de messages entre un EDI et un serveur de langage pendant une session d'édition de code. De plus, le LSP supporte la cancellation de requête et le rapport de progression. Grâce à cela, il est possible de canceller des requêtes en cours et d'obtenir des réponses partielles.

Les interactions entre le client et le serveur se basent sur des modèles indépendants du langage de programmation et de l'EDI. Par exemple, lorsqu'un client souhaite accéder à la définition d'une procédure, il échange un Uniform Resource Identifier (URI) avec le serveur pour localiser un document sur disque et une position dans ce document. Le LSP permet également au serveur de signaler quelles fonctionnalités il prend en charge, laissant au client la gestion de la durée de vie du serveur.

Monto est une architecture qui connecte un EDI à des composants offrant des fonctionnalités de langage, adoptant une approche orientée service. Chaque fonctionnalité de langage, comme l'autocomplétion, est fournie par un service qui peut être décomposé en sous-services. L'architecture permet à l'EDI de connaître les fonctionnalités disponibles enregistrées auprès d'une composante appelée broker. Un module d'extension dans l'EDI gère la communication avec le broker. La figure illustre une vue d'ensemble de l'interaction entre les composants de l'architecture Monto.

L'architecture Monto définit deux types de messages : les messages source et les messages produit. Les messages source, envoyés du module d'extension de l'EDI vers le broker, contiennent un identifiant unique, le nom du fichier, le langage de programmation et le contenu du fichier. Le broker distribue les messages source aux services appropriés et répond au module d'extension de l'EDI lorsque les opérations sont terminées. Les messages produits encapsulent une représentation intermédiaire générique, indépendante du langage et de l'EDI. Les communications sont effectuées via ZeroMQ, une bibliothèque de messagerie asynchrone haute performance, avec l'encodage des messages au format JSON. Cette approche permet d'avoir un serveur sans état et n'exige pas de conserver une copie des documents ouverts, contrairement au LSP. Cependant, l'envoi du contenu complet d'un fichier au format JSON peut ne pas être optimal en termes de transfert de données sur le réseau.


\subsection{Language Server Index Format Specification}

Language Server Index Format (LSIF) est un protocole et un format de données utilisés dans le cadre du LSP. LSIF a été développé pour améliorer les performances et l'efficacité de la communication entre l'éditeur de code et le serveur de langage. Il s'agit de générer et de stocker un index des informations du projet source, ce qui permet de réduire les délais de réponse lors de l'interaction avec le code source.

1. Génération de l'index : Le serveur de langage génère un index LSIF en analysant le projet source. Cet index contient des informations sur la structure du code, les définitions de fonctions, les variables, les références croisées, etc.

2. Stockage de l'index : Une fois généré, l'index LSIF est stocké dans un fichier ou une base de données. Ce fichier est souvent enregistré à un emplacement spécifique du projet.

3. Utilisation par l'éditeur de code : Lorsque l'utilisateur interagit avec le code source dans l'éditeur, celui-ci peut interroger l'index LSIF pour obtenir des informations pertinentes, telles que des suggestions de complétion, la documentation, ou pour effectuer des actions de refactoring. Cela permet à l'éditeur de code de répondre plus rapidement aux demandes de l'utilisateur, car il n'a pas besoin de re-analyser tout le projet à chaque interaction.

LSIF est particulièrement utile pour les projets de grande envergure où l'analyse statique du code peut être coûteuse en termes de ressources. En utilisant un index pré-généré, les performances de l'éditeur de code s'améliorent significativement.

En résumé, LSIF est un format d'indexation utilisé dans le cadre du protocole LSP pour améliorer les performances de l'interaction entre les éditeurs de code et les serveurs de langage lors de la programmation. Il permet de stocker des informations structurées sur le code source, ce qui facilite la fourniture de fonctionnalités avancées aux développeurs.


\subsection{Trace Server Protocol}

Le TSP a été développée lors de l'introduction de l'architecture client-serveur dans Trace Compass par Chen Kuang Piao en 2018. Ce protocol suit la philosophie des REST API et utilise actuellement JSON comme format d'échange de données. Cependant, le travail de Chen Kuang Piao a suggéré qu'il serait possible d'obtenir des améliorations significatives en termes de taille des messages et d'efficacité de sérialisation/désérialisation en utilisant Protobuf à la place. En sachant que la sérialisation/désérialisation devient un facteur très important dans le temps de réponse lorsque nous essayons de traiter des traces énormes [Article de Hao]. Il devient alors très important d'évaluer les solutions existantes qui nous permettrait de réduire l'impact de la sérialisation/désérialisation. Un impact qui devient encore plus important lorsque nous essayons de transitionner vers une architecture distribué qui risque de nécessité plusieurs communications réseaux, et donc plusieurs sérialisations/désérialisations pour une seule requête. 

La transition vers un autre protocol est envisageable, car REST, en tant qu'approche, n'est pas lié à un format de données spécifique, mais plus au ressource accessible par les différentes d'accès. En plus des points d'accès permettant de récupérer des données de traces ou de sessions d'analyse, les points d'accès pour obtenir le modèle de visualisation des traces sont organisés par type de visualisation. Il existe des points d'accès dédiés aux analyses sous forme de graphes XY, au graphe temporel et sous forme de trableau. À savoir que le protocol est en pleine évolution. Alors il est important de considérer que le protocole risque de divaguer de ses objectif primaire en terme de principe, comme le standard RESTful. 

Dans le protocole TSP, il est possible d'ajuster la résolution des données, ainsi que les items souhaitées en spécifiant les points de temps souhaités en tant que paramètres. Cette pratique n'est pas courante dans les normes REST qui n'impliquent généralement pas de filtrage des réponses dans le corps de la requête, mais plutôt dans les paramètres de la requête. À exception, nous retrouvons des paramètres de filtrage dans le corps de la requête lorsque nous rencontrons un problème lié à la limite de caractère possible dans un URL.

% (Chen Kuang Piao, 2018) [16] \cite{chen2021distributed}
% (Ericsson) [42] \cite{Ericsson_TSP_OPENAPI}
% [41] \cite{github_ericsson_TSP}




\section{Conclusion de la revue littéraire}



% \section{Related Work}

% The related work is divided into six sections. The first section detail recent work on Tracing Analysis. The second section report recent work on integrated development environment. The third section present different distributed architecture that application use for scaling. The fourth section expose recent work on distributed analysis. The fifth section report recent work on distributed critical path. The sixth section present recent work on Theia.

% \subsection{Integrated Development Environment}
% % \subsection{Scaling Distributed Architecture}

% % Modern Internet services are often implemented as complex, large-scale distributed systems. These applications are constructed from collections of software modules that may be developed by different teams, perhaps in different programming languages, and could span many thousands of machines across multiple physical facilities. Tools that aid in understanding system behavior and reasoning about performance issues are invaluable in such an environment.

% % Artificial Intelligence (AI) and cloud computing has emerged as a promising avenue for addressing the growing computational demands of AI applications. Parallel and distributed training of AI models become increasingly complex. Parallel and distributed training techniques have emerged as essential approaches to reduce training time and improve resource utilization. By leveraging these techniques, researchers and practitioners can accelerate the training process, enhance model performance, and reduce costs associated with cloud-based AI systems[Article 11].

% % Resource demands of HPC applications vary significantly. The varying resource demands can lead to HPC resources being not fully utilized. It becomes very difficult for HPC systems to find the reasons for throttling jobs. [Article 13]

% % [Article 14]



% \subsection{Distributed Analysis}

% Recent efforts to parallelize trace analysis, as exemplified by the work of Reumont-Locke (2015) \cite{reumont2015methodes} and Martin (2018) \cite{Martin2018}, have aimed to enhance the efficiency of this process. Nevertheless, optimizing efficiency alone cannot fully address the scalability challenges inherent in distributed environments. Even if a trace analysis tool operates at peak efficiency, it remains constrained by the computational capabilities of the underlying hardware, typically equivalent to the traced system in the best-case scenario. When we scale up the number of traced nodes to hundreds or thousands, the analysis tool quickly becomes overwhelmed. This bottleneck becomes particularly problematic in applications requiring continuous uptime, as anomalies can rapidly escalate within clusters (Matloff) \cite{matloff2011programming}, and delays in data analysis during investigations only exacerbate the situation.

% A similar approach observed in distributed tracing platforms involves deploying multiple tracers, each running on a traced machine, with all trace data being transmitted to a central collector for subsequent analysis. In some instances, these tracers take the form of client libraries, allowing for the creation of custom events with application-specific information, in contrast to the more opaque black-box tracing approach of tools like Nagios. Prometheus addresses scalability concerns by enabling the organization of Prometheus instances into a federation, as demonstrated by Reback in 2021 \cite{Logz.io_prometheus_2023}. This approach facilitates the establishment of a multi-level hierarchy of Prometheus servers, with each level aggregating and forwarding data to the level above. Notably, Nagios also adopted a similar approach to mitigate its own scalability challenges (Nagios) \cite{Nagios2019}.

% While horizontally scaling analysis servers is an effective strategy, it is essential to recognize that Prometheus analyses primarily consist of simple metrics, making aggregation feasible. However, applying the same model to more complex analysis processes, such as those offered by Trace Compass, presents substantial challenges. The nature of their aggregations varies significantly between different analysis types, making direct application of the Prometheus approach difficult in such cases.

% \subsection{Distributed Critical Path}

% Recent efforts to parallelize critical path analysis, as exemplified by the work of Denis and Dagenais, have aimed to enhance the efficiency of this process. The kernel events necessary for analysis execution are identified. A distributed architecture that did not require any file transfer between the client and traced nodes, and allowed the distribution of trace analysis computation is presented. They also explore the algorithm to resolve the remote dependencies \cite{matloff2011programming}.

% Although distributed architectures offer a solution to the scalability problem, it is challenging to fully leverage their benefits due to network communication when broadcasting to all nodes. This is why restricting communications solely to the node essential for the calculation is crucial \cite{denys2023distributed}.


% \subsection{Theia - Trace Viewer Extension}

% Eﬀtinge and Kosyakov have presented Theia (Eﬀtinge and Kosyakov, 2017), a new open-
% source IDE framework for building IDEs that could run both as a desktop application or in
% a web browser connected to a remote backend. The project shares a lot of similarities with
% Microsoft code editor, Visual Studio Code. Theia uses Node.js, Electron and implements
% the LSP.


% Theia Trace Viewer extension is the newly developed server-client application developed by Ericsson and the Eclipse Foundation, along with other contributors. It purpose is to replace Trace Compass as the Eclipse general-purpose tracing tool. As previously described Trace Viewer uses a server-client architecture, where the client communicates with the server through a protocol called Trace Server Protocol (TSP) \cite{desnoyers2006lttng}.
