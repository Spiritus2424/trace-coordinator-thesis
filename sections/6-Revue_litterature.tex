\Chapter{REVUE DE LITTÉRATURE / LITERATURE REVIEW}\label{sec:RevLitt}

\section{Trace}

\subsection{Analyse de trace}

Le traçage implique une utilisation spécialisée de la journalisation qui enregistre les événements d'exécution concernant l'exécution d'un programme. Le traçage est utilisé pour détecter et identifier les problèmes de performances, les problèmes de comportement et les problèmes de sécurité (TROUVEZ LA SOURCE ICI). Le traçage peut être effectué à plusieurs niveaux, notamment l'espace utilisateur, le noyau, le matériel, l'hyperviseur, le réseau, etc. Le logiciel qui capture ces événements est appelé traceur. Pour capturer ces événements, les points de trace doivent être insérés de manière statique ou dynamique. Dans le cas où le point de trace est inséré de manière statique, le code doit être modifié pour inclure les macros de traçage et doit être recompilé. Dans le cas où le point de trace est inséré dynamiquement, les points de trace sont ajoutés dynamiquement à un programme compilé et en cours d'exécution \cite{gregg2011dtrace}. Lors de l'exécution du programme, des événements seront émis et un traceur les capturera. À ce stade, un traceur produira un fichier de trace, organisé dans un format spécifique. Étant donné que le traceur doit s'exécuter en même temps que l'application principale, cela aura un impact sur le temps d'exécution de l'application principale. C'est pourquoi un traceur doit avoir une surcharge d'exécution minimale. Lorsque le traceur a fini de produire un fichier de trace, nous pouvons appliquer une analyse de trace.

Linux inclut perf \cite{kernelPerfWiki}, un ensemble d'outils qui utilisent l'infrastructure perf\_event\_open \cite{man7Perf}. Ces outils puissants couvrent un large éventail d'informations liées aux performances disponibles pour le système d'exploitation. Les fonctionnalités disponibles incluent l'échantillonnage basé sur un compteur de performances, certains points d'instrumentation, la journalisation pour enregistrer les informations collectées et la visualisation sous forme de profils textuels. Cependant, perf utilise un format de fichier monolithique et ne dispose pas d'un moyen évolutif et convivial pour analyser et visualiser les délais résultants. Auparavant, nous utilisions perf pour la surveillance des performances et convertissions la trace résultante dans un format de fichier différent permettant l'utilisation d'outils de visualisation de chronologie \cite{schone2014scalable}.

OProfile \cite{sourceforgeAboutOProfile} est un profileur statistique non intrusif construit sur l'infrastructure \textit{perf\_event-\_open}. Il prend en charge la surveillance à faible coût de l'ensemble du système et des processus uniques, mais est limité aux profils agrégés uniquement.

Une analyse de trace transforme les événements de trace en un ensemble de données pour effectuer plus d'investigation et les réorganise en structure de données pour un accès plus rapide \cite{prieur2018r}.

HPCToolkit \cite{adhianto2010hpctoolkit} est une suite d'outils d'analyse des performances qui se concentre sur l'échantillonnage d'applications parallèles, prenant en charge MPI et OpenMP. Il utilise la synthèse pour fournir des profils de performances. De plus, une vue chronologique basée sur la journalisation est disponible. HPCToolkit comprend des informations provenant d'échantillons de pile d'appels qui sont traités dans l'espace utilisateur avec des techniques de déroulement sophistiquées et des compteurs de performances de l'interface de programmation d'applications de performances.

Trace Viewer est une extension open source disponible dans l'IDE Theia. Il utilise le protocole Trace-Server-Protocol pour interroger les modèles de données et visualiser différentes analyses de trace. Une analyse de trace lit une trace de manière séquentielle et stocke ses résultats (appelés modèles d'état) dans une structure de données pouvant être écrite sur disque. À partir des événements de trace, l'analyse extrairait les intervalles des valeurs d'état pour différentes ressources système (CPU, processus, disques, etc.). \cite{chen2021distributed}


\subsection{Outils de visualisation de trace}

Eﬀtinge et Kosyakov ont présenté Theia \cite{theia_2017}, un nouveau logiciel libre cadriciel pour les EDI. Theia a été mis de l'avant pour montrer la prochaine génération d'EDI après Eclipse. L'architecture de Theia a été penser pour être extensible, supporter plusieurs languages, supporter le lancement et le déboguage d'application. L'avantage principal de Theia est qui pourra être exécuter dans les navigateurs web et en local comme une application de bureau directement sur le système d'exploitation. Theia est un cadriciel d'EDI ce qui signifie qu'il est sera utilisé pour créer d'autre EDI qui auront toutes les avantages que Theia offre, mais personnaliser pour les besoins de l'utilisateur.

Le projet partage de nombreuses similitudes avec l'éditeur de code Microsoft, Visual Studio Code au niveau des technologies, de l'interface graphique et les personnalisations de l'EDI par plugins. Theia utilise Node.js, Electron comme technologie et implémente les protocoles LSP et DAP. Theia permet également d'installer des extensions lors de la compilation pour qu'elle fasse partie intégrante de l'EDI lors de la distribution. Les extensions entre Theia et VsCode sont compatibles.

L'extension Theia Trace Viewer est la nouvelle application serveur-client développée par Ericsson et la Fondation Eclipse, avec d'autres contributeurs. Son objectif est de remplacer Trace Compass en tant qu'outil de traçage à usage général d'Eclipse. Comme décrit précédemment, Trace Viewer utilise une architecture serveur-client, dans laquelle le client communique avec le serveur via un protocole appelé Trace Server Protocol (TSP). \cite{desnoyers2006lttng} L'extension s'intègre dans l'EDI permettant de programmer, de tracer et de visualiser avec un outil et permet d'itérer plus rapidement dans les différentes phases de développement. L'extension permet de visualiser les traces sous plusieurs vues selon les analyses disponibles pour la trace dans le serveur.

Grafana est une plateforme libre logiciel qui fournit des fonctionnalités pour interroger, visualiser et comprendre les mesures. Grafana a répondu aux questions sur la façon de visualiser les données, ce qui a mis au défi de nombreux développeurs ces dernières années. Grafana apporte toutes les données ensemble et les partage entre les équipes. Grâce à divers plugins, les utilisateurs peuvent obtenir ce qui leur convient le plus, ou même créer des plugins adaptés à leurs besoins. Grafana offre plusieurs fonctionnalités pour permettre à l'utilisateur de visualiser les données, d'organiser les données ou même de notifier sur différente plateforme tel que slack ou PagerDuty. Grafana peut également se connecter à différente source de donnée externe tels que Excel, une base de donnée SQL et immédiatement permettre de visualiser ses données. Cela est très pratique puisque Grafana interprête directement les données au lieu de le faire manuellement ce qui nous sauve une étape qui peut parfois prendre du temps. Il permet également d'afficher plusieurs source de données différentes dans la même vue. Grafana est assez simple lorsqu'il est temps d'afficher les données. Après s'être connecté au différente source de donnée, l'utilisateur doit créer construire une requête pour extraire l'information pertinent. Ensuite, pour le cas d'utilisation l'utilisateur choisir l'outil de visualisation. \cite{do2021data} Grafana ne s'occupe par n'en plus d'instrumenter les applications, mais laisse plûtot le travail à d'autre outil plus spécialisé pour ce traitement comme Prometheus. À prendre en compte que Grafana n'offre pas des analyses sur un ensemble de donnée comme Trace Compass offre, mais réellement la possibilité d'afficher différentes données selon la requête construite.


% Vampire \cite{Mix_2018}


\section{Traçage distribué}

\subsection{Système distribué}

\subsection{Outils de traçage distribué}

% Recent efforts to parallelize trace analysis, as exemplified by the work of Reumont-Locke (2015) \cite{reumont2015methodes} and Martin (2018) \cite{Martin2018}, have aimed to enhance the efficiency of this process. Nevertheless, optimizing efficiency alone cannot fully address the scalability challenges inherent in distributed environments. Even if a trace analysis tool operates at peak efficiency, it remains constrained by the computational capabilities of the underlying hardware, typically equivalent to the traced system in the best-case scenario. When we scale up the number of traced nodes to hundreds or thousands, the analysis tool quickly becomes overwhelmed. This bottleneck becomes particularly problematic in applications requiring continuous uptime, as anomalies can rapidly escalate within clusters (Matloff) \cite{matloff2011programming}, and delays in data analysis during investigations only exacerbate the situation.

% A similar approach observed in distributed tracing platforms involves deploying multiple tracers, each running on a traced machine, with all trace data being transmitted to a central collector for subsequent analysis. In some instances, these tracers take the form of client libraries, allowing for the creation of custom events with application-specific information, in contrast to the more opaque black-box tracing approach of tools like Nagios. Prometheus addresses scalability concerns by enabling the organization of Prometheus instances into a federation, as demonstrated by Reback in 2021 \cite{Logz.io_prometheus_2023}. This approach facilitates the establishment of a multi-level hierarchy of Prometheus servers, with each level aggregating and forwarding data to the level above. Notably, Nagios also adopted a similar approach to mitigate its own scalability challenges (Nagios) \cite{Nagios2019}.

% While horizontally scaling analysis servers is an effective strategy, it is essential to recognize that Prometheus analyses primarily consist of simple metrics, making aggregation feasible. However, applying the same model to more complex analysis processes, such as those offered by Trace Compass, presents substantial challenges. The nature of their aggregations varies significantly between different analysis types, making direct application of the Prometheus approach difficult in such cases.


\subsection{Outils de visualisation de trace distribué}


\section{Architecture distribué}

\subsection{Client-serveur}

\subsection{Pair-à-pair}

\subsection{Maître-Ouvrier}


\section{Interopérabilité de système hétérogène}

\subsection{REST}

\subsection{GraphQL}

\subsection{JSON-RPC}

\subsection{gRPC}

\subsection{Language Server Protocol}

Le Language Server Protocol (LSP) est un protocole de communication basé sur JSON-RPC, développé par Microsoft, qui permet l'interaction entre un éditeur ou un environnement de développement intégré (EDI) et un serveur de langage de programmation \cite{Keidel2016}. Un serveur de langage fournit diverses fonctionnalités telles que l'autocomplétion de code, la coloration syntaxique, la navigation vers la définition, et la signalisation des erreurs dans le code. L'objectif principal du LSP est de standardiser la manière dont ces fonctionnalités sont mises à disposition des EDI. Cela permet de rendre l'implémentation d'un EDI indépendante du serveur de langage, favorisant ainsi la réutilisation des serveurs de langage dans différents EDI. Initialement conçu pour VS Code, le LSP a évolué grâce à la contribution d'organisations telles que Red Hat et Codeenvy. Plusieurs entreprises, dont la fondation Eclipse, Github, Sourcegraph et Red Hat, ont adapté leurs outils de développement populaires, tels qu'Eclipse, Atom, IntelliJ, Emacs, Sublime, pour prendre en charge le protocole. Actuellement, plus de 200 langages de programmation, y compris Java, C/C++, C\#, PHP, Python et JavaScript, prennent en charge le LSP.

Le LSP définit trois types de messages : les requêtes, les réponses et les notifications. Les requêtes sont initiées par le client en utilisant des appels de procédures JSON-RPC, et le serveur répond à chaque requête par une réponse. Les notifications peuvent être envoyées par le serveur ou le client, sans le retour d'une réponse. La figure X ci-dessous illustre un exemple d'interaction et d'échange de messages entre un EDI et un serveur de langage pendant une session d'édition de code. De plus, le LSP supporte la cancellation de requête et le rapport de progression. Grâce à cela, il est possible de canceller des requêtes en cours et d'obtenir des réponses partielles.

    [Figure https://microsoft.github.io/language-server-protocol/overviews/lsp/img/language-server-sequence.png ]

Les interactions entre le client et le serveur se basent sur des modèles indépendants du langage de programmation et de l'EDI. Par exemple, lorsqu'un client souhaite accéder à la définition d'une procédure, il échange un Uniform Resource Identifier (URI) avec le serveur pour localiser un document sur disque et une position dans ce document. Le LSP permet également au serveur de signaler quelles fonctionnalités il prend en charge, laissant au client la gestion de la durée de vie du serveur.

Monto est une architecture qui connecte un EDI à des composants offrant des fonctionnalités de langage, adoptant une approche orientée service. Chaque fonctionnalité de langage, comme l'autocomplétion, est fournie par un service qui peut être décomposé en sous-services. L'architecture permet à l'EDI de connaître les fonctionnalités disponibles enregistrées auprès d'une composante appelée broker. Un module d'extension dans l'EDI gère la communication avec le broker. La figure X illustre une vue d'ensemble de l'interaction entre les composants de l'architecture Monto.

    [Figure de l'architecture Monto avec un broker]


L'architecture Monto définit deux types de messages : les messages source et les messages produit. Les messages source, envoyés du module d'extension de l'EDI vers le broker, contiennent un identifiant unique, le nom du fichier, le langage de programmation et le contenu du fichier. Le broker distribue les messages source aux services appropriés et répond au module d'extension de l'EDI lorsque les opérations sont terminées. Les messages produits encapsulent une représentation intermédiaire générique, indépendante du langage et de l'EDI. Les communications sont effectuées via ZeroMQ, une bibliothèque de messagerie asynchrone haute performance, avec l'encodage des messages au format JSON. Cette approche permet d'avoir un serveur sans état et n'exige pas de conserver une copie des documents ouverts, contrairement au LSP. Cependant, l'envoi du contenu complet d'un fichier au format JSON peut ne pas être optimal en termes de transfert de données sur le réseau.


\subsection{Language Server Index Format Specification}

Language Server Index Format (LSIF) est un protocole et un format de données utilisés dans le cadre du LSP. LSIF a été développé pour améliorer les performances et l'efficacité de la communication entre l'éditeur de code et le serveur de langage. Il s'agit de générer et de stocker un index des informations du projet source, ce qui permet de réduire les délais de réponse lors de l'interaction avec le code source.

1. Génération de l'index : Le serveur de langage génère un index LSIF en analysant le projet source. Cet index contient des informations sur la structure du code, les définitions de fonctions, les variables, les références croisées, etc.

2. Stockage de l'index : Une fois généré, l'index LSIF est stocké dans un fichier ou une base de données. Ce fichier est souvent enregistré à un emplacement spécifique du projet.

3. Utilisation par l'éditeur de code : Lorsque l'utilisateur interagit avec le code source dans l'éditeur, celui-ci peut interroger l'index LSIF pour obtenir des informations pertinentes, telles que des suggestions de complétion, la documentation, ou pour effectuer des actions de refactoring. Cela permet à l'éditeur de code de répondre plus rapidement aux demandes de l'utilisateur, car il n'a pas besoin de re-analyser tout le projet à chaque interaction.

LSIF est particulièrement utile pour les projets de grande envergure où l'analyse statique du code peut être coûteuse en termes de ressources. En utilisant un index pré-généré, les performances de l'éditeur de code s'améliorent significativement.

En résumé, LSIF est un format d'indexation utilisé dans le cadre du protocole LSP pour améliorer les performances de l'interaction entre les éditeurs de code et les serveurs de langage lors de la programmation. Il permet de stocker des informations structurées sur le code source, ce qui facilite la fourniture de fonctionnalités avancées aux développeurs.


\subsection{Trace Server Protocol}

Le TSP a été développée lors de l'introduction de l'architecture client-serveur dans Trace Compass par Chen Kuang Piao en 2018. Ce protocol suit la philosophie des REST API et utilise actuellement JSON comme format d'échange de données. Cependant, le travail de Chen Kuang Piao a suggéré qu'il serait possible d'obtenir des améliorations significatives en termes de taille des messages et d'efficacité de sérialisation/désérialisation en utilisant Protobuf à la place. En sachant que la sérialisation/désérialisation devient un facteur très important dans le temps de réponse lorsque nous essayons de traiter des traces énormes [Article de Hao]. Il devient alors très important d'évaluer les solutions existantes qui nous permettrait de réduire l'impact de la sérialisation/désérialisation. Un impact qui devient encore plus important lorsque nous essayons de transitionner vers une architecture distribué qui risque de nécessité plusieurs communications réseaux, et donc plusieurs sérialisations/désérialisations pour une seule requête.

La transition vers un autre protocol est envisageable, car REST, en tant qu'approche, n'est pas lié à un format de données spécifique, mais plus au ressource accessible par les différentes d'accès. En plus des points d'accès permettant de récupérer des données de traces ou de sessions d'analyse, les points d'accès pour obtenir le modèle de visualisation des traces sont organisés par type de visualisation. Il existe des points d'accès dédiés aux analyses sous forme de graphes XY, au graphe temporel et sous forme de trableau. À savoir que le protocol est en pleine évolution. Alors il est important de considérer que le protocole risque de divaguer de ses objectif primaire en terme de principe, comme le standard RESTful.

Dans le protocole TSP, il est possible d'ajuster la résolution des données, ainsi que les items souhaitées en spécifiant les points de temps souhaités en tant que paramètres. Cette pratique n'est pas courante dans les normes REST qui n'impliquent généralement pas de filtrage des réponses dans le corps de la requête, mais plutôt dans les paramètres de la requête. À exception, nous retrouvons des paramètres de filtrage dans le corps de la requête lorsque nous rencontrons un problème lié à la limite de caractère possible dans un URL.

% (Chen Kuang Piao, 2018) [16] \cite{chen2021distributed}
% (Ericsson) [42] \cite{Ericsson_TSP_OPENAPI}
% [41] \cite{github_ericsson_TSP}




\section{Conclusion de la revue littéraire}

% A travers cette revue de littérature, nous avons vu que la modularisation de Trace Compass a créé la fondation pour pouvoir le déployer dans un environnement distribué et qu'il existe plusieurs travaux autour du sujet du traçage distribué qui se concentrent sur différentes parties. Nous avons aussi vu que le flux de travail instrumentation-collection-analyse-visualisation/alerte est aussi commun en dehors du domaine du traçage. Toutes ces applications proposent aussi des modèles robustes avec la mise à l'échelle en tête. Pourtant, les opérateurs d'agrégation dans ces outils, s'il y a lieu, sont souvent prédéfinis et fortement couplés avec le format de trace et l'écosystème, malgré qu'ils possèdent un langage de requête puissant. Cela gêne l'adaptation lors des cas d'usage spécifiques et force les utilisateurs à réinventer la logique.

% En conséquence, nous souhaitons d'abord proposer une organisation qui permet un fonctionnement efficace sur des grappes de calcul pour Trace Compass, en s'inspirant de l'architecture des outils de trace distribués à l'état de l'art. Avec cette nouvelle architecture, nous proposons ensuite une extension du protocole actuel permettant de construire un modèle de programmation qui facilite le développement de nouveaux types d'agrégation dans la visualisation de trace.


% \section{Related Work}

% The related work is divided into six sections. The first section detail recent work on Tracing Analysis. The second section report recent work on integrated development environment. The third section present different distributed architecture that application use for scaling. The fourth section expose recent work on distributed analysis. The fifth section report recent work on distributed critical path. The sixth section present recent work on Theia.

% \subsection{Integrated Development Environment}
% % \subsection{Scaling Distributed Architecture}

% % Modern Internet services are often implemented as complex, large-scale distributed systems. These applications are constructed from collections of software modules that may be developed by different teams, perhaps in different programming languages, and could span many thousands of machines across multiple physical facilities. Tools that aid in understanding system behavior and reasoning about performance issues are invaluable in such an environment.

% % Artificial Intelligence (AI) and cloud computing has emerged as a promising avenue for addressing the growing computational demands of AI applications. Parallel and distributed training of AI models become increasingly complex. Parallel and distributed training techniques have emerged as essential approaches to reduce training time and improve resource utilization. By leveraging these techniques, researchers and practitioners can accelerate the training process, enhance model performance, and reduce costs associated with cloud-based AI systems[Article 11].

% % Resource demands of HPC applications vary significantly. The varying resource demands can lead to HPC resources being not fully utilized. It becomes very difficult for HPC systems to find the reasons for throttling jobs. [Article 13]

% % [Article 14]



% \subsection{Distributed Analysis}

% Recent efforts to parallelize trace analysis, as exemplified by the work of Reumont-Locke (2015) \cite{reumont2015methodes} and Martin (2018) \cite{Martin2018}, have aimed to enhance the efficiency of this process. Nevertheless, optimizing efficiency alone cannot fully address the scalability challenges inherent in distributed environments. Even if a trace analysis tool operates at peak efficiency, it remains constrained by the computational capabilities of the underlying hardware, typically equivalent to the traced system in the best-case scenario. When we scale up the number of traced nodes to hundreds or thousands, the analysis tool quickly becomes overwhelmed. This bottleneck becomes particularly problematic in applications requiring continuous uptime, as anomalies can rapidly escalate within clusters (Matloff) \cite{matloff2011programming}, and delays in data analysis during investigations only exacerbate the situation.

% A similar approach observed in distributed tracing platforms involves deploying multiple tracers, each running on a traced machine, with all trace data being transmitted to a central collector for subsequent analysis. In some instances, these tracers take the form of client libraries, allowing for the creation of custom events with application-specific information, in contrast to the more opaque black-box tracing approach of tools like Nagios. Prometheus addresses scalability concerns by enabling the organization of Prometheus instances into a federation, as demonstrated by Reback in 2021 \cite{Logz.io_prometheus_2023}. This approach facilitates the establishment of a multi-level hierarchy of Prometheus servers, with each level aggregating and forwarding data to the level above. Notably, Nagios also adopted a similar approach to mitigate its own scalability challenges (Nagios) \cite{Nagios2019}.

% While horizontally scaling analysis servers is an effective strategy, it is essential to recognize that Prometheus analyses primarily consist of simple metrics, making aggregation feasible. However, applying the same model to more complex analysis processes, such as those offered by Trace Compass, presents substantial challenges. The nature of their aggregations varies significantly between different analysis types, making direct application of the Prometheus approach difficult in such cases.

% \subsection{Distributed Critical Path}

% Recent efforts to parallelize critical path analysis, as exemplified by the work of Denis and Dagenais, have aimed to enhance the efficiency of this process. The kernel events necessary for analysis execution are identified. A distributed architecture that did not require any file transfer between the client and traced nodes, and allowed the distribution of trace analysis computation is presented. They also explore the algorithm to resolve the remote dependencies \cite{matloff2011programming}.

% Although distributed architectures offer a solution to the scalability problem, it is challenging to fully leverage their benefits due to network communication when broadcasting to all nodes. This is why restricting communications solely to the node essential for the calculation is crucial \cite{denys2023distributed}.


% \subsection{Theia - Trace Viewer Extension}

% Eﬀtinge and Kosyakov have presented Theia (Eﬀtinge and Kosyakov, 2017), a new open-
% source IDE framework for building IDEs that could run both as a desktop application or in
% a web browser connected to a remote backend. The project shares a lot of similarities with
% Microsoft code editor, Visual Studio Code. Theia uses Node.js, Electron and implements
% the LSP.


% Theia Trace Viewer extension is the newly developed server-client application developed by Ericsson and the Eclipse Foundation, along with other contributors. It purpose is to replace Trace Compass as the Eclipse general-purpose tracing tool. As previously described Trace Viewer uses a server-client architecture, where the client communicates with the server through a protocol called Trace Server Protocol (TSP) \cite{desnoyers2006lttng}.
