\Chapter{REVUE DE LITTÉRATURE / LITERATURE REVIEW}\label{sec:RevLitt}

\section{Trace}

\subsection{Analyse de trace}

Le traçage implique une utilisation spécialisée de la journalisation qui enregistre les événements d'exécution concernant l'exécution d'un programme. Le traçage est utilisé pour détecter et identifier les problèmes de performances, les problèmes de comportement et les problèmes de sécurité (TROUVEZ LA SOURCE ICI). Le traçage peut être effectué à plusieurs niveaux, notamment l'espace utilisateur, le noyau, le matériel, l'hyperviseur, le réseau, etc. Le logiciel qui capture ces événements est appelé traceur. Pour capturer ces événements, les points de trace doivent être insérés de manière statique ou dynamique. Dans le cas où le point de trace est inséré de manière statique, le code doit être modifié pour inclure les macros de traçage et doit être recompilé. Dans le cas où le point de trace est inséré dynamiquement, les points de trace sont ajoutés dynamiquement à un programme compilé et en cours d'exécution \cite{gregg2011dtrace}. Lors de l'exécution du programme, des événements seront émis et un traceur les capturera. À ce stade, un traceur produira un fichier de trace, organisé dans un format spécifique. Étant donné que le traceur doit s'exécuter en même temps que l'application principale, cela aura un impact sur le temps d'exécution de l'application principale. C'est pourquoi un traceur doit avoir une surcharge d'exécution minimale. Lorsque le traceur a fini de produire un fichier de trace, nous pouvons appliquer une analyse de trace.

Linux inclut perf \cite{kernelPerfWiki}, un ensemble d'outils qui utilisent l'infrastructure perf\_event\_open \cite{man7Perf}. Ces outils puissants couvrent un large éventail d'informations liées aux performances disponibles pour le système d'exploitation. Les fonctionnalités disponibles incluent l'échantillonnage basé sur un compteur de performances, certains points d'instrumentation, la journalisation pour enregistrer les informations collectées et la visualisation sous forme de profils textuels. Cependant, perf utilise un format de fichier monolithique et ne dispose pas d'un moyen évolutif et convivial pour analyser et visualiser les délais résultants. Auparavant, nous utilisions perf pour la surveillance des performances et convertissions la trace résultante dans un format de fichier différent permettant l'utilisation d'outils de visualisation de chronologie \cite{schone2014scalable}.

OProfile \cite{sourceforgeAboutOProfile} est un profileur statistique non intrusif construit sur l'infrastructure \textit{perf\_event-\_open}. Il prend en charge la surveillance à faible coût de l'ensemble du système et des processus uniques, mais est limité aux profils agrégés uniquement.

Une analyse de trace transforme les événements de trace en un ensemble de données pour effectuer plus d'investigation et les réorganise en structure de données pour un accès plus rapide \cite{prieur2018r}.

HPCToolkit \cite{adhianto2010hpctoolkit} est une suite d'outils d'analyse des performances qui se concentre sur l'échantillonnage d'applications parallèles, prenant en charge MPI et OpenMP. Il utilise la synthèse pour fournir des profils de performances. De plus, une vue chronologique basée sur la journalisation est disponible. HPCToolkit comprend des informations provenant d'échantillons de pile d'appels qui sont traités dans l'espace utilisateur avec des techniques de déroulement sophistiquées et des compteurs de performances de l'interface de programmation d'applications de performances.

Trace Viewer est une extension open source disponible dans l'IDE Theia. Il utilise le protocole Trace-Server-Protocol pour interroger les modèles de données et visualiser différentes analyses de trace. Une analyse de trace lit une trace de manière séquentielle et stocke ses résultats (appelés modèles d'état) dans une structure de données pouvant être écrite sur disque. À partir des événements de trace, l'analyse extrairait les intervalles des valeurs d'état pour différentes ressources système (CPU, processus, disques, etc.). \cite{chen2021distributed}



\subsection{Outils de visualisation de trace}

Efftinge et Kosyakov ont présenté Theia \cite{theia_2017}, un nouveau logiciel libre cadriciel pour les EDI. Theia a été mis de l'avant pour montrer la prochaine génération d'EDI après Eclipse. L'architecture de Theia a été penser pour être extensible, supporter plusieurs languages, supporter le lancement et le déboguage d'application. L'avantage principal de Theia est qui pourra être exécuter dans les navigateurs web et en local comme une application de bureau directement sur le système d'exploitation. Theia est un cadriciel d'EDI ce qui signifie qu'il est sera utilisé pour créer d'autre EDI qui auront toutes les avantages que Theia offre, mais personnaliser pour les besoins de l'utilisateur.


Le projet partage de nombreuses similitudes avec l'éditeur de code Microsoft, Visual Studio Code au niveau des technologies, de l'interface graphique et les personnalisations de l'EDI par plugins. Theia utilise Node.js, Electron comme technologie et implémente les protocoles LSP et DAP. Theia permet également d'installer des extensions lors de la compilation pour qu'elle fasse partie intégrante de l'EDI lors de la distribution. Les extensions entre Theia et VsCode sont compatibles.

% Theia
L'extension Theia Trace Viewer est la nouvelle application serveur-client développée par Ericsson et la Fondation Eclipse, avec d'autres contributeurs. Son objectif est de remplacer Trace Compass en tant qu'outil de traçage à usage général d'Eclipse. Comme décrit précédemment, Trace Viewer utilise une architecture serveur-client, dans laquelle le client communique avec le serveur via un protocole appelé Trace Server Protocol (TSP). \cite{desnoyers2006lttng} L'extension s'intègre dans l'EDI permettant de programmer, de tracer et de visualiser avec un outil et permet d'itérer plus rapidement dans les différentes phases de développement. L'extension permet de visualiser les traces sous plusieurs vues selon les analyses disponibles pour la trace dans le serveur.


% Grafana
Grafana est une plateforme libre logiciel qui fournit des fonctionnalités pour interroger, visualiser et comprendre les mesures. Grafana a répondu aux questions sur la façon de visualiser les données, ce qui a mis au défi de nombreux développeurs ces dernières années. Grafana apporte toutes les données ensemble et les partage entre les équipes. Grâce à divers plugins, les utilisateurs peuvent obtenir ce qui leur convient le plus, ou même créer des plugins adaptés à leurs besoins. Grafana offre plusieurs fonctionnalités pour permettre à l'utilisateur de visualiser les données, d'organiser les données ou même de notifier sur différente plateforme tel que slack ou PagerDuty. Grafana peut également se connecter à différente source de donnée externe tels que Excel, une base de donnée SQL et immédiatement permettre de visualiser ses données. Cela est très pratique puisque Grafana interprête directement les données au lieu de le faire manuellement ce qui nous sauve une étape qui peut parfois prendre du temps. Il permet également d'afficher plusieurs source de données différentes dans la même vue. Grafana est assez simple lorsqu'il est temps d'afficher les données. Après s'être connecté au différente source de donnée, l'utilisateur doit créer construire une requête pour extraire l'information pertinent. Ensuite, pour le cas d'utilisation l'utilisateur choisir l'outil de visualisation. \cite{do2021data} Grafana ne s'occupe par n'en plus d'instrumenter les applications, mais laisse plûtot le travail à d'autre outil plus spécialisé pour ce traitement comme Prometheus. À prendre en compte que Grafana n'offre pas des analyses sur un ensemble de donnée comme Trace Compass offre, mais réellement la possibilité d'afficher différentes données selon la requête construite.


% Vampir
Vampir fournit un cadre facile à utiliser qui permet aux développeurs d'afficher et d'analyser rapidement le comportement arbitraire d'un programme. La suite d'outils implémente des algorithmes d'analyse d'événements optimisés et des affichages personnalisables \cite{GmbH_Vampir}. L'optimisation des performances avec Vampir implique plusieurs étapes pour améliorer les performances des applications informatiques parallèles et hautes performances. Vampir est un outil d'analyse des performances souvent utilisé en conjonction avec l'instrumentation Score-P pour collecter des données sur les performances des applications \cite{Mix_2018}. Le processus commence généralement par l'instrumentation de votre code et son exécution, en collectant des données. Vampir est ensuite utilisé pour visualiser et analyser ces données. L'analyse se concentre sur l'identification des goulots d'étranglement, tels que les algorithmes inefficaces, les modèles d'accès aux données problématiques, les charges de travail déséquilibrées et les zones à forte utilisation du processeur. Les modèles de communication et de synchronisation sont essentiels, et Vampir aide à évaluer comment les processus communiquent et où se produit la surcharge de synchronisation. Les modèles d'utilisation de la mémoire sont également examinés, car une consommation élevée de mémoire et un accès inefficace à la mémoire peuvent affecter les performances. Les stratégies de parallélisation sont évaluées et des modifications sont apportées en fonction des informations tirées de l'analyse Vampir. Ces changements peuvent impliquer des modifications d'algorithmes, une optimisation des structures de données, une réduction des transferts de données et un meilleur équilibrage de charge. Une analyse comparative continue est cruciale pour mesurer l'impact des efforts d'optimisation. Pour les systèmes distribués, Vampir peut être utilisé pour le profilage parallèle, vous permettant d'analyser les performances sur plusieurs noeuds. La collaboration et la documentation des résultats sont essentielles, car des perspectives multiples et des efforts collectifs conduisent souvent à des solutions d'optimisation plus efficaces. En résumé, Vampir est un outil précieux dans le processus itératif d'optimisation des performances, qui implique un profilage, une analyse minutieuse et des modifications du code.


\section{Traçage distribué}

Les efforts récents pour paralléliser l'analyse des traces, comme en témoignent les travaux de Reumont-Locke (2015) \cite{reumont2015methodes} et Martin (2018) \cite{Martin2018}, ont visé à améliorer l'efficacité de ce processus. Néanmoins, l'optimisation de l'efficacité ne peut à elle seule répondre pleinement aux défis d'évolutivité inhérents aux environnements distribués. Même si un outil d'analyse de trace fonctionne avec une efficacité maximale, il reste limité par les capacités de calcul du matériel sous-jacent, généralement équivalentes au système tracé dans le meilleur des cas. Lorsque nous augmentons le nombre de nœuds tracés jusqu'à des centaines ou des milliers, l'outil d'analyse devient rapidement submergé. Ce goulot d'étranglement devient particulièrement problématique dans les applications nécessitant une disponibilité continue, car les anomalies peuvent rapidement s'aggraver au sein des clusters (Matloff) \cite{matloff2011programming}, et les retards dans l'analyse des données pendant les enquêtes ne font qu'exacerber la situation.

Une approche similaire observée dans les plateformes de traçage distribuées implique le déploiement de plusieurs traceurs, chacun fonctionnant sur une machine tracée, toutes les données de trace étant transmises à un collecteur central pour une analyse ultérieure. Dans certains cas, ces traceurs prennent la forme de bibliothèques client, permettant la création d'événements personnalisés avec des informations spécifiques à l'application, contrairement à l'approche de traçage plus opaque en boîte noire d'outils comme Nagios. Prometheus répond aux problèmes d'évolutivité en permettant l'organisation des instances Prometheus dans une fédération, comme l'a démontré Reback en 2021 \cite{Logz.io_prometheus_2023}. Cette approche facilite l'établissement d'une hiérarchie à plusieurs niveaux de serveurs Prometheus, chaque niveau regroupant et transmettant les données au niveau supérieur. Notamment, Nagios a également adopté une approche similaire pour atténuer ses propres défis d'évolutivité \cite{Nagios2019}.

Bien que la mise à l'échelle horizontale des serveurs d'analyse soit une stratégie efficace, il est essentiel de reconnaître que les analyses Prometheus consistent principalement en des métriques simples, ce qui rend l'agrégation possible. Cependant, appliquer le même modèle à des processus d'analyse plus complexes, tels que ceux proposés par Trace Compass, présente des défis considérables. La nature de leurs agrégations varie considérablement selon les différents types d'analyse, ce qui rend difficile l'application directe de l’approche Prometheus dans de tels cas.

\subsection{Système distribué}

\subsection{Outils de traçage distribué}

Les efforts récents pour paralléliser l'analyse des traces, comme en témoignent les travaux de Reumont-Locke \cite{reumont2015methodes} et Martin \cite{Martin2018}, ont visé à améliorer l'efficacité de ce processus. Néanmoins, l'optimisation de l'efficacité ne peut à elle seule répondre pleinement aux défis d'évolutivité inhérents aux environnements distribués. Même si un outil d'analyse de trace fonctionne avec une efficacité maximale, il reste limité par les capacités de calcul du matériel sous-jacent, généralement équivalentes au système tracé dans le meilleur des cas. Lorsque nous augmentons le nombre de nœuds tracés jusqu'à des centaines ou des milliers, l'outil d'analyse devient rapidement submergé. Ce goulot d'étranglement devient particulièrement problématique dans les applications nécessitant une disponibilité continue, car les anomalies peuvent rapidement s'aggraver au sein des clusters \cite{matloff2011programming}, et les retards dans l'analyse des données pendant les enquêtes ne font qu'exacerber la situation.

Une approche similaire observée dans les plateformes de traçage distribuées implique le déploiement de plusieurs traceurs, chacun fonctionnant sur une machine tracée, toutes les données de trace étant transmises à un collecteur central pour une analyse ultérieure. Dans certains cas, ces traceurs prennent la forme de bibliothèques client, permettant la création d'événements personnalisés avec des informations spécifiques à l'application, contrairement à l'approche de traçage plus opaque en boîte noire d'outils comme Nagios. Prometheus répond aux problèmes d'évolutivité en permettant l'organisation des instances Prometheus dans une fédération, comme l'a démontré Reback en 2021 \cite{Logz.io_prometheus_2023}. Cette approche facilite l'établissement d'une hiérarchie à plusieurs niveaux de serveurs Prometheus, chaque niveau regroupant et transmettant les données au niveau supérieur. Notamment, Nagios a également adopté une approche similaire pour atténuer ses propres défis d'évolutivité (Nagios) \cite{Nagios2019}.

Bien que la mise à l'échelle horizontale des serveurs d'analyse soit une stratégie efficace, il est essentiel de reconnaître que les analyses Prometheus consistent principalement en des métriques simples, ce qui rend l'agrégation possible. Cependant, appliquer le même modèle à des processus d'analyse plus complexes, tels que ceux proposés par Trace Compass, présente des défis considérables. La nature de leurs agrégations varie considérablement selon les différents types d'analyse, ce qui rend difficile l'application directe de l'approche Prometheus dans de tels cas.


\subsection{Outils de visualisation de trace distribué}

Les efforts récents pour paralléliser l'analyse du chemin critique, comme en témoignent les travaux de Denis et Dagenais, ont visé à améliorer l'efficacité de ce processus. Les événements de noyau nécessaires à l'exécution de l'analyse sont identifiés. Une architecture distribuée qui ne nécessite aucun transfert de fichiers entre le client et les noeuds tracés et permet la distribution du calcul d'analyse de trace est présentée. Ils explorent également l'algorithme pour résoudre les dépendances distantes \cite{matloff2011programming}.

Bien que les architectures distribuées offrent une solution au problème d'évolutivité, il est difficile d'exploiter pleinement leurs avantages dus à la communication réseau lors de la diffusion vers tous les noeuds. C'est pourquoi restreindre les communications uniquement au nœud essentiel au calcul est crucial \cite{denys2023distributed}.

\section{Architecture distribué}

Les services Internet modernes sont souvent mis en oeuvre sous la forme de systèmes distribués complexes à grande échelle. Ces applications sont construites à partir d'ensembles de modules logiciels qui peuvent être développés par différentes équipes, peut-être dans différents langages de programmation, et peuvent s'étendre sur plusieurs milliers de machines réparties dans plusieurs installations physiques. Il devient de plus en plus important de choisir sa prochaine architecture avec des critères à long terme \cite{Martens_2010}. Une mauvaise architecture peut créer énormément de traffic et même réduire la qualité du service \cite{Kolny_2023}. Les outils qui aident à comprendre le comportement du système et à raisonner sur les problèmes de performances sont inestimables dans un tel environnement.

L'intelligence artificielle (IA) et le cloud computing sont apparus comme une voie prometteuse pour répondre aux demandes informatiques croissantes des applications d'IA. La formation parallèle et distribuée des modèles d'IA devient de plus en plus complexe. Les techniques de formation parallèles et distribuées sont apparues comme des approches essentielles pour réduire le temps de formation et améliorer l'utilisation des ressources. En tirant parti de ces techniques, les chercheurs et les praticiens peuvent accélérer le processus de formation, améliorer les performances des modèles et réduire les coûts associés aux systèmes d'IA basés sur le cloud \cite{mungoli2023scalable}.

Les demandes en ressources des applications HPC varient considérablement. Les demandes variables en ressources peuvent conduire à ce que les ressources HPC ne soient pas pleinement utilisées. Il devient très difficile pour les systèmes HPC de trouver les raisons de la limitation des tâches. \cite{li2023analyzing}

\subsection{Client-serveur}

\subsection{Pair-à-pair}

\subsection{Maître-Ouvrier}


\section{Interopérabilité de système hétérogène}

\subsection{REST}

\subsection{GraphQL}

\subsection{JSON-RPC}

\subsection{gRPC}

\subsection{Language Server Protocol}

Le Language Server Protocol (LSP) est un protocole de communication basé sur JSON-RPC, développé par Microsoft, qui permet l'interaction entre un éditeur ou un environnement de développement intégré (EDI) et un serveur de langage de programmation \cite{Keidel2016}. Un serveur de langage fournit diverses fonctionnalités telles que l'autocomplétion de code, la coloration syntaxique, la navigation vers la définition, et la signalisation des erreurs dans le code. L'objectif principal du LSP est de standardiser la manière dont ces fonctionnalités sont mises à disposition des EDI. Cela permet de rendre l'implémentation d'un EDI indépendante du serveur de langage, favorisant ainsi la réutilisation des serveurs de langage dans différents EDI. Initialement conçu pour VS Code, le LSP a évolué grâce à la contribution d'organisations telles que Red Hat et Codeenvy. Plusieurs entreprises, dont la fondation Eclipse, Github, Sourcegraph et Red Hat, ont adapté leurs outils de développement populaires, tels qu'Eclipse, Atom, IntelliJ, Emacs, Sublime, pour prendre en charge le protocole. Actuellement, plus de 200 langages de programmation, y compris Java, C/C++, C\#, PHP, Python et JavaScript, prennent en charge le LSP.

Le LSP définit trois types de messages : les requêtes, les réponses et les notifications. Les requêtes sont initiées par le client en utilisant des appels de procédures JSON-RPC, et le serveur répond à chaque requête par une réponse. Les notifications peuvent être envoyées par le serveur ou le client, sans le retour d'une réponse. La figure X ci-dessous illustre un exemple d'interaction et d'échange de messages entre un EDI et un serveur de langage pendant une session d'édition de code. De plus, le LSP supporte la cancellation de requête et le rapport de progression. Grâce à cela, il est possible de canceller des requêtes en cours et d'obtenir des réponses partielles.

    [Figure https://microsoft.github.io/language-server-protocol/overviews/lsp/img/language-server-sequence.png ]

Les interactions entre le client et le serveur se basent sur des modèles indépendants du langage de programmation et de l'EDI. Par exemple, lorsqu'un client souhaite accéder à la définition d'une procédure, il échange un Uniform Resource Identifier (URI) avec le serveur pour localiser un document sur disque et une position dans ce document. Le LSP permet également au serveur de signaler quelles fonctionnalités il prend en charge, laissant au client la gestion de la durée de vie du serveur.

Monto est une architecture qui connecte un EDI à des composants offrant des fonctionnalités de langage, adoptant une approche orientée service. Chaque fonctionnalité de langage, comme l'autocomplétion, est fournie par un service qui peut être décomposé en sous-services. L'architecture permet à l'EDI de connaître les fonctionnalités disponibles enregistrées auprès d'une composante appelée broker. Un module d'extension dans l'EDI gère la communication avec le broker. La figure X illustre une vue d'ensemble de l'interaction entre les composants de l'architecture Monto.

    [Figure de l'architecture Monto avec un broker]


L'architecture Monto définit deux types de messages : les messages source et les messages produit. Les messages source, envoyés du module d'extension de l'EDI vers le broker, contiennent un identifiant unique, le nom du fichier, le langage de programmation et le contenu du fichier. Le broker distribue les messages source aux services appropriés et répond au module d'extension de l'EDI lorsque les opérations sont terminées. Les messages produits encapsulent une représentation intermédiaire générique, indépendante du langage et de l'EDI. Les communications sont effectuées via ZeroMQ, une bibliothèque de messagerie asynchrone haute performance, avec l'encodage des messages au format JSON. Cette approche permet d'avoir un serveur sans état et n'exige pas de conserver une copie des documents ouverts, contrairement au LSP. Cependant, l'envoi du contenu complet d'un fichier au format JSON peut ne pas être optimal en termes de transfert de données sur le réseau.


\subsection{Language Server Index Format Specification}

Language Server Index Format (LSIF) est un protocole et un format de données utilisés dans le cadre du LSP. LSIF a été développé pour améliorer les performances et l'efficacité de la communication entre l'éditeur de code et le serveur de langage. Il s'agit de générer et de stocker un index des informations du projet source, ce qui permet de réduire les délais de réponse lors de l'interaction avec le code source.

1. Génération de l'index : Le serveur de langage génère un index LSIF en analysant le projet source. Cet index contient des informations sur la structure du code, les définitions de fonctions, les variables, les références croisées, etc.

2. Stockage de l'index : Une fois généré, l'index LSIF est stocké dans un fichier ou une base de données. Ce fichier est souvent enregistré à un emplacement spécifique du projet.

3. Utilisation par l'éditeur de code : Lorsque l'utilisateur interagit avec le code source dans l'éditeur, celui-ci peut interroger l'index LSIF pour obtenir des informations pertinentes, telles que des suggestions de complétion, la documentation, ou pour effectuer des actions de refactoring. Cela permet à l'éditeur de code de répondre plus rapidement aux demandes de l'utilisateur, car il n'a pas besoin de re-analyser tout le projet à chaque interaction.

LSIF est particulièrement utile pour les projets de grande envergure où l'analyse statique du code peut être coûteuse en termes de ressources. En utilisant un index pré-généré, les performances de l'éditeur de code s'améliorent significativement.

En résumé, LSIF est un format d'indexation utilisé dans le cadre du protocole LSP pour améliorer les performances de l'interaction entre les éditeurs de code et les serveurs de langage lors de la programmation. Il permet de stocker des informations structurées sur le code source, ce qui facilite la fourniture de fonctionnalités avancées aux développeurs.


\subsection{Trace Server Protocol}

Le TSP a été développée lors de l'introduction de l'architecture client-serveur dans Trace Compass par Chen Kuang Piao en 2018. Ce protocol suit la philosophie des REST API et utilise actuellement JSON comme format d'échange de données. Cependant, le travail de Chen Kuang Piao a suggéré qu'il serait possible d'obtenir des améliorations significatives en termes de taille des messages et d'efficacité de sérialisation/désérialisation en utilisant Protobuf à la place. En sachant que la sérialisation/désérialisation devient un facteur très important dans le temps de réponse lorsque nous essayons de traiter des traces énormes [Article de Hao]. Il devient alors très important d'évaluer les solutions existantes qui nous permettrait de réduire l'impact de la sérialisation/désérialisation. Un impact qui devient encore plus important lorsque nous essayons de transitionner vers une architecture distribué qui risque de nécessité plusieurs communications réseaux, et donc plusieurs sérialisations/désérialisations pour une seule requête.

La transition vers un autre protocol est envisageable, car REST, en tant qu'approche, n'est pas lié à un format de données spécifique, mais plus au ressource accessible par les différentes d'accès. En plus des points d'accès permettant de récupérer des données de traces ou de sessions d'analyse, les points d'accès pour obtenir le modèle de visualisation des traces sont organisés par type de visualisation. Il existe des points d'accès dédiés aux analyses sous forme de graphes XY, au graphe temporel et sous forme de trableau. À savoir que le protocol est en pleine évolution. Alors il est important de considérer que le protocole risque de divaguer de ses objectif primaire en terme de principe, comme le standard RESTful.

Dans le protocole TSP, il est possible d'ajuster la résolution des données, ainsi que les items souhaitées en spécifiant les points de temps souhaités en tant que paramètres. Cette pratique n'est pas courante dans les normes REST qui n'impliquent généralement pas de filtrage des réponses dans le corps de la requête, mais plutôt dans les paramètres de la requête. À exception, nous retrouvons des paramètres de filtrage dans le corps de la requête lorsque nous rencontrons un problème lié à la limite de caractère possible dans un URL.

% (Chen Kuang Piao, 2018) [16] \cite{chen2021distributed}
% (Ericsson) [42] \cite{Ericsson_TSP_OPENAPI}
% [41] \cite{github_ericsson_TSP}




\section{Conclusion de la revue littéraire}

% A travers cette revue de littérature, nous avons vu que la modularisation de Trace Compass a créé la fondation pour pouvoir le déployer dans un environnement distribué et qu'il existe plusieurs travaux autour du sujet du traçage distribué qui se concentrent sur différentes parties. Nous avons aussi vu que le flux de travail instrumentation-collection-analyse-visualisation/alerte est aussi commun en dehors du domaine du traçage. Toutes ces applications proposent aussi des modèles robustes avec la mise à l'échelle en tête. Pourtant, les opérateurs d'agrégation dans ces outils, s'il y a lieu, sont souvent prédéfinis et fortement couplés avec le format de trace et l'écosystème, malgré qu'ils possèdent un langage de requête puissant. Cela gêne l'adaptation lors des cas d'usage spécifiques et force les utilisateurs à réinventer la logique.

% En conséquence, nous souhaitons d'abord proposer une organisation qui permet un fonctionnement efficace sur des grappes de calcul pour Trace Compass, en s'inspirant de l'architecture des outils de trace distribués à l'état de l'art. Avec cette nouvelle architecture, nous proposons ensuite une extension du protocole actuel permettant de construire un modèle de programmation qui facilite le développement de nouveaux types d'agrégation dans la visualisation de trace.

