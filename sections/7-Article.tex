\Chapter{Article 1}\label{sec:architecture}

\section{Introduction}

\section{Related Work}

The related work is divided into six sections. The ﬁrst section will report recent works on Tracing Analysis. The second section will report recent works on integrated development environment. The third section will present different distributed artchitecture that application use for scaling. The fourth section will present recent works on distributed analysis. The fifth section will prensent recent works on dsitributed critical path. The sixth section will present recent works on Theia.


\subsection{Tracing Analysis}

 Tracing involves a specialized use of logging that records runtime events about a program's execution. Tracing is used to detect and identify performance issues, behavior issues and security issues (FIND SOURCE HERE). Tracing can be done on several levels including user-space, kernel, hardware, hypervisor, network, etc. Software that capture those events is called a tracer. To capture those events, tracepoints must be inserted either statically or dynamically. In the case that the tracepoint is inserted statically, the code must be modified to include tracing macros and must be recompiled. In the case that the tracepoint is inserted dynamically, tracepoints are added dynamically to a compiled and running program (Gregg and Mauro, 2011). During the execution of the program, events will be emitted and a tracer will capture them. At this point, a tracer will produce a trace file, organized in a specific format. Because the tracer have to run at the same time of the main application, it will impact the execution time of the main application. This is why a tracer must have a minimal execution overhead. When the tracer finish to produce a trace file, we can apply a trace analysis.

 A trace analysis transforms the trace events into a dataset to perform more investigation and it reorganizes them into data structure for faster access (Prieur-Drevon et al., 2018).

 \subsection{Integrated Development Environment}
 
 % IDE evolution: No plugins, Plugins, Server Protocol, Desktop base IDE, Cloud base IDE, Hybrid base IDE
% Integrated Development Environments (IDEs) have played a pivotal role in shaping the landscape of software development. These powerful software tools have evolved significantly over the years, revolutionizing the way developers write, debug, and maintain code. These IDEs greatly enhanced developer productivity and set the stage for more sophisticated tools. IDEs like Microsoft Visual Studio provided comprehensive solutions for building complex software applications. Developers could now easily navigate through code, leverage libraries, and visually design user interfaces within a single environment. It is clear those IDEs help developers to be more and more productive, depending on the developing phase. The developers get a lot of support from IDEs. The problem is, each time that we add features in IDEs, it become more harder for developer to reach the  productive stage [Article 5]. That is why developers start using IDEs that have basic feature of an text editor and enhance it, using plugins and extension, to become a full featured IDE [Article 6]. 


% Different Server Protocol aujourd'hui mis en place
A lot of work as been put to decouple the support of programming language such as code completion, code error, syntax highlighting and go-to definition. The objective was to enable the support of many programming language using language service [Article 8]. Microsoft's language server protocol (LSP) is a communication protocol, based on JSON-RPC, between a client, which is the IDE, and a server that offers language support. The protocol provides common features such as code completion, code error, syntax highlighting and go-to definition and many more. Many organizations such as the Eclipse Foundation and JetBrains are adapting or creating IDE (Eclipse, IntelliJ) to implement the LSP [Article 7]. 

In the same way, a lot of work as been put to decouple the debugging tools and the IDEs. Microsoft's debugger adapter protocol (DAP) is implement in Visual Studio Code and Theia. The base protocol exchanges messages that consist of a header and a content part (comparable to HTTP). Josselin et al. proposed a protocol that supports meaningful Domain-Specific Languages (DSLs) and that can be used with minimal effort within an IDE that implement DAP. This debugger allowing a generic interactive debugger to communicate with heterogeneous DSL runtime [Article 10]. 

Marr et al. have presented the Kómpos protocol [Article 9] which proposes a concurrency-agnostic debugger protocol that decouples the debugger from the concurrency models employed by the target application. As a result, the underlying language runtime can define custom breakpoints, stepping operations, and execution events for each concurrency model it supports, and a debugger can expose them without having to be specifically adapted. In comparison to existing debugger protocol such as Java Debug Wire Protocol (JDWP) or the GNU Debugger (GDB) machine interface or the Chrome DevTools protocol or Visual Studio Code debug protocol, Kómpos protocol solution is not specific to a concurrency concept.

\subsection{Scaling Distributed Architecture}

Modern Internet services are often implemented as complex, large-scale distributed systems. These applications are constructed from collections of software modules that may be developed by different teams, perhaps in different programming languages, and could span many thousands of machines across multiple physical facilities. Tools that aid in understanding system behavior and reasoning about performance issues are invaluable in such an environment.

Artificial Intelligence (AI) and cloud computing has emerged as a promising avenue for addressing the growing computational demands of AI applications. Parallel and distributed training of AI models become increasingly complex. Parallel and distributed training techniques have emerged as essential approaches to reduce training time and improve resource utilization. By leveraging these techniques, researchers and practitioners can accelerate the training process, enhance model performance, and reduce costs associated with cloud-based AI systems[Article 11].

% Resource demands of HPC applications vary significantly. The varying resource demands can lead to HPC resources being not fully utilized. It becomes very difficult for HPC systems to find the reasons for throttling jobs. [Article 13]

% [Article 14]



\subsection{Distributed Analysis}

% Indeed, trace ﬁles could easily contain millions, even billions of events and the analysis must use an efficient data structure to maintain query performance

Recent efforts to parallelize trace analysis, as exemplified by the work of Reumont-Locke (2015) [17] and Martin (2018) [Article 18], have aimed to enhance the efficiency of this process. Nevertheless, optimizing efficiency alone cannot fully address the scalability challenges inherent in distributed environments. Even if a trace analysis tool operates at peak efficiency, it remains constrained by the computational capabilities of the underlying hardware, typically equivalent to the traced system in the best-case scenario. When we scale up the number of traced nodes to hundreds or thousands, the analysis tool quickly becomes overwhelmed. This bottleneck becomes particularly problematic in applications requiring continuous uptime, as anomalies can rapidly escalate within clusters (Matloff) [20], and delays in data analysis during investigations only exacerbate the situation.

A similar approach observed in distributed tracing platforms involves deploying multiple tracers, each running on a traced machine, with all trace data being transmitted to a central collector for subsequent analysis. In some instances, these tracers take the form of client libraries, allowing for the creation of custom events with application-specific information, in contrast to the more opaque black-box tracing approach of tools like Nagios. Prometheus addresses scalability concerns by enabling the organization of Prometheus instances into a federation, as demonstrated by Reback in 2021 [32]. This approach facilitates the establishment of a multi-level hierarchy of Prometheus servers, with each level aggregating and forwarding data to the level above. Notably, Nagios also adopted a similar approach to mitigate its own scalability challenges (Nagios) [30].

While horizontally scaling analysis servers is an effective strategy, it's essential to recognize that Prometheus analyses primarily consist of simple metrics, making aggregation feasible. However, applying the same model to more complex analysis processes, such as those offered by Trace Compass, presents substantial challenges. The nature of their aggregations varies significantly between different analysis types, making direct application of the Prometheus approach difficult in such cases.

\subsection{Distributed Critical Path}

Recent efforts to parallelize critical path analysis, as exemplified by the work of Denis and Dagenais, have aimed to enhance the efficiency of this process. The kernel events necessary for analysis execution are identified. A distributed architecture that did not require any file transfer between the client and traced nodes, and allowed the distribution of trace analysis computation is presented. They also explore the algorithm to resolve the remote depencies. [Article 19]

Although distributed architectures offer a solution to the scalability problem, it's challenging to fully leverage their benefits due to network communication when broadcasting to all nodes. This is why restricting communications solely to the node essential for the calculation is crucial [Article 20].


\subsection{Theia - Trace Viewer Extension}

Eﬀtinge and Kosyakov have presented Theia (Eﬀtinge and Kosyakov, 2017), a new open-
source IDE framework for building IDEs that could run both as a desktop application or in
a web browser connected to a remote backend. The project shares a lot of similarities with
Microsoft's code editor, Visual Studio Code. Theia uses Node.js, Electron and implements
the LSP.


Theia Trace Viewer extension is the newly developed server-client application developed by Ericsson and the Eclipse Foundation, along with other contributors. It's purpose is to replace Trace Compass as the Eclipse general-purpose tracing tool. As previously described Trace Viewer uses a server-client architecture, where the client communicates with the server through a protocol called Trace Server Protocol (TSP) [10].

\section{Proposed Solution}
\subsection{Overall architecture}
\subsection{}
% \subsection{Connect logically the traces}
% \subsubsection{What are the available traces}
% \subsubsection{Where are the traces}
% \subsubsection{How to connect the traces}

\subsection{Distributed Analysis}

\subsubsection{Aggregation of independent trace (vertically)}

\subsubsection{Critical Path}

\subsection{Visualization}

\section{Test Environment}

\subsection{Computer Specification}

\subsection{Generate Config file}

\subsection{Deployment}

\section{Results}

\subsection{Trace API with(out) Coordinator}

\subsection{Experiment API with(out) Coordiantor}

\subsection{Timegraph API with(out) Coordiantor}

\subsection{Xy Graph API with(out) Coordiantor}

\subsection{Virtual Table API with(out) Coordiantor}

\subsection{Critical Path Analysis with(out) Coordiantor}

\section{Discusssion}

\section{Conclusion}

\section{Acknowledgement}